---
title:  "Word2vec and Game of Thrones"
excerpt: "Combining Game of Thrones subtitles and Word2Vec"
tags: 
  - GoT
  - python
  - nlp
---

Following [this post](https://phelipetls.github.io/game-of-thrones-text-mining) by Phelipe Teles, and because it takes so long until the episode 3, I decided to play a bit with Game of Thrones subtitles. And since I wanted to use Word2vec for a while, it was an obvious choice.

Now, we should not expect too much from this. Word2vec hates small datasets. And Game of Thrones subtitles are a small dataset, with only 40k observations. Even worse, the subtitles usually consist of very short sentences, in fact most of them with 5 words or less, so we are not getting much context here. Very likely, our model will lead to some weird and inconsistent results.


## The dataset and cleaning it up

The subtitles, in json format, can be obtained [here](https://www.kaggle.com/gunnvant/game-of-thrones-srt). The `pandas` package, handily, has `.read_json`, so no extra tools were needed. Due to the format of the original file, `.read_json` insisted in reading each season as a separate column, so a small transformation with `.melt` was necessary to store the subs as one column, and season and episode as another.

Then, I read all 7 seasons into a list, and concatenated it into a single dataframe.

```
import numpy as np
import pandas as pd

#Read the season into a dataframe and reformat it
def get_season(season):
    temp = pd.read_json('season' + str(season) + '.json')
    temp = pd.melt(temp, value_vars=list(temp), value_name='text').dropna()
    return temp

#Create a list and read the files into it	
li = []
for i in range(1, 8):
    li.append(get_season(i))

#Concatenate into single dataframe
got_subs = pd.concat(li, axis=0, ignore_index=True)

```

As I do not plan using season and episode in the analysis, I will not bother with extracting this info, and will leave it as a one column mash-up instead.



